{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "STAT 453: Deep Learning (Spring 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/  \n",
    "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![](figures/adaline-concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that linear regression and Adaline are very similar. The only difference is that we apply a threshold function for converting the outputs from continuous targets for predictions. The derivative and training procedure are identical to Adaline though. You can compare the two notebooks (this one and `adaline-sgd.ipynb`) side by side as shown below to see the relationship:\n",
    "\n",
    "![](figures/adaline-vs-linreg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load & Prepare a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    float64\n",
      "X2    float64\n",
      "X3    float64\n",
      "X4    float64\n",
      "X5    float64\n",
      "X6      int64\n",
      "X7    float64\n",
      "X8      int64\n",
      "Y1    float64\n",
      "Y2    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ENB2012_data.csv', index_col=False)\n",
    "df.tail()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assign features and target\n",
    "\n",
    "X = torch.tensor(df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']].values, dtype=torch.float)\n",
    "y = torch.tensor(df['Y2'].values, dtype=torch.float)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "percent80 = int(shuffle_idx.size(0)*0.8)\n",
    "\n",
    "X_train, X_test = X[shuffle_idx[:percent80]], X[shuffle_idx[percent80:]]\n",
    "y_train, y_test = y[shuffle_idx[:percent80]], y[shuffle_idx[percent80:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance), standardization.\n",
    "\n",
    "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implement Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression1():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = torch.add(torch.mm(x, self.weights), self.bias)\n",
    "        activations = netinputs\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):\n",
    "\n",
    "        # (yhat - y)^2  --> this is our loss function\n",
    "        # deriv: 2*(y - yhat)\n",
    "        \n",
    "        grad_loss_yhat = 2*(y - yhat)\n",
    "        \n",
    "        grad_yhat_weights = -x\n",
    "        grad_yhat_bias = -1.\n",
    "        \n",
    "        # Chain rule: inner times outer\n",
    "        grad_loss_weights =  torch.mm(grad_yhat_weights.t(),\n",
    "                                         grad_loss_yhat.view(-1, 1)) / y.size(0)\n",
    "\n",
    "        grad_loss_bias = torch.sum(grad_yhat_bias*grad_loss_yhat) / y.size(0)\n",
    "        \n",
    "        # return negative gradient\n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def loss(yhat, y): # mean squared error\n",
    "    return torch.mean((yhat - y)**2)\n",
    "\n",
    "# Batch Gradient Descent\n",
    "def train(model, x, y, num_epochs, learning_rate=0.01):\n",
    "    cost = []\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        #### Compute outputs ####\n",
    "        yhat = model.forward(x)\n",
    "\n",
    "        #### Compute gradients ####\n",
    "        negative_grad_w, negative_grad_b = model.backward(x, yhat, y)\n",
    "\n",
    "        #### Update weights and bias ####\n",
    "        model.weights += learning_rate * negative_grad_w\n",
    "        model.bias += learning_rate * negative_grad_b\n",
    "\n",
    "        #### Logging ####\n",
    "        yhat = model.forward(x) # note that this is a bit wasteful here\n",
    "        curr_loss = loss(yhat, y)\n",
    "        print('Epoch: %03d' % (e+1), end=\"\")\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | MSE: 536.39227\n",
      "Epoch: 002 | MSE: 427.21774\n",
      "Epoch: 003 | MSE: 344.45737\n",
      "Epoch: 004 | MSE: 279.70889\n",
      "Epoch: 005 | MSE: 228.19989\n",
      "Epoch: 006 | MSE: 186.87184\n",
      "Epoch: 007 | MSE: 153.56898\n",
      "Epoch: 008 | MSE: 126.67381\n",
      "Epoch: 009 | MSE: 104.92837\n",
      "Epoch: 010 | MSE: 87.33533\n",
      "Epoch: 011 | MSE: 73.09612\n",
      "Epoch: 012 | MSE: 61.56806\n",
      "Epoch: 013 | MSE: 52.23269\n",
      "Epoch: 014 | MSE: 44.67114\n",
      "Epoch: 015 | MSE: 38.54483\n",
      "Epoch: 016 | MSE: 33.57999\n",
      "Epoch: 017 | MSE: 29.55510\n",
      "Epoch: 018 | MSE: 26.29100\n",
      "Epoch: 019 | MSE: 23.64273\n",
      "Epoch: 020 | MSE: 21.49301\n",
      "Epoch: 021 | MSE: 19.74689\n",
      "Epoch: 022 | MSE: 18.32757\n",
      "Epoch: 023 | MSE: 17.17287\n",
      "Epoch: 024 | MSE: 16.23246\n",
      "Epoch: 025 | MSE: 15.46561\n",
      "Epoch: 026 | MSE: 14.83934\n",
      "Epoch: 027 | MSE: 14.32697\n",
      "Epoch: 028 | MSE: 13.90689\n",
      "Epoch: 029 | MSE: 13.56159\n",
      "Epoch: 030 | MSE: 13.27690\n",
      "Epoch: 031 | MSE: 13.04135\n",
      "Epoch: 032 | MSE: 12.84566\n",
      "Epoch: 033 | MSE: 12.68230\n",
      "Epoch: 034 | MSE: 12.54518\n",
      "Epoch: 035 | MSE: 12.42936\n",
      "Epoch: 036 | MSE: 12.33084\n",
      "Epoch: 037 | MSE: 12.24640\n",
      "Epoch: 038 | MSE: 12.17340\n",
      "Epoch: 039 | MSE: 12.10973\n",
      "Epoch: 040 | MSE: 12.05365\n",
      "Epoch: 041 | MSE: 12.00378\n",
      "Epoch: 042 | MSE: 11.95899\n",
      "Epoch: 043 | MSE: 11.91835\n",
      "Epoch: 044 | MSE: 11.88113\n",
      "Epoch: 045 | MSE: 11.84672\n",
      "Epoch: 046 | MSE: 11.81463\n",
      "Epoch: 047 | MSE: 11.78447\n",
      "Epoch: 048 | MSE: 11.75592\n",
      "Epoch: 049 | MSE: 11.72872\n",
      "Epoch: 050 | MSE: 11.70264\n",
      "Epoch: 051 | MSE: 11.67754\n",
      "Epoch: 052 | MSE: 11.65325\n",
      "Epoch: 053 | MSE: 11.62967\n",
      "Epoch: 054 | MSE: 11.60670\n",
      "Epoch: 055 | MSE: 11.58427\n",
      "Epoch: 056 | MSE: 11.56232\n",
      "Epoch: 057 | MSE: 11.54080\n",
      "Epoch: 058 | MSE: 11.51967\n",
      "Epoch: 059 | MSE: 11.49888\n",
      "Epoch: 060 | MSE: 11.47842\n",
      "Epoch: 061 | MSE: 11.45826\n",
      "Epoch: 062 | MSE: 11.43838\n",
      "Epoch: 063 | MSE: 11.41877\n",
      "Epoch: 064 | MSE: 11.39941\n",
      "Epoch: 065 | MSE: 11.38029\n",
      "Epoch: 066 | MSE: 11.36141\n",
      "Epoch: 067 | MSE: 11.34274\n",
      "Epoch: 068 | MSE: 11.32430\n",
      "Epoch: 069 | MSE: 11.30607\n",
      "Epoch: 070 | MSE: 11.28804\n",
      "Epoch: 071 | MSE: 11.27021\n",
      "Epoch: 072 | MSE: 11.25258\n",
      "Epoch: 073 | MSE: 11.23514\n",
      "Epoch: 074 | MSE: 11.21790\n",
      "Epoch: 075 | MSE: 11.20084\n",
      "Epoch: 076 | MSE: 11.18396\n",
      "Epoch: 077 | MSE: 11.16727\n",
      "Epoch: 078 | MSE: 11.15075\n",
      "Epoch: 079 | MSE: 11.13441\n",
      "Epoch: 080 | MSE: 11.11825\n",
      "Epoch: 081 | MSE: 11.10226\n",
      "Epoch: 082 | MSE: 11.08644\n",
      "Epoch: 083 | MSE: 11.07078\n",
      "Epoch: 084 | MSE: 11.05530\n",
      "Epoch: 085 | MSE: 11.03997\n",
      "Epoch: 086 | MSE: 11.02481\n",
      "Epoch: 087 | MSE: 11.00981\n",
      "Epoch: 088 | MSE: 10.99497\n",
      "Epoch: 089 | MSE: 10.98029\n",
      "Epoch: 090 | MSE: 10.96576\n",
      "Epoch: 091 | MSE: 10.95138\n",
      "Epoch: 092 | MSE: 10.93716\n",
      "Epoch: 093 | MSE: 10.92308\n",
      "Epoch: 094 | MSE: 10.90916\n",
      "Epoch: 095 | MSE: 10.89538\n",
      "Epoch: 096 | MSE: 10.88175\n",
      "Epoch: 097 | MSE: 10.86826\n",
      "Epoch: 098 | MSE: 10.85492\n",
      "Epoch: 099 | MSE: 10.84171\n",
      "Epoch: 100 | MSE: 10.82864\n",
      "Epoch: 101 | MSE: 10.81571\n",
      "Epoch: 102 | MSE: 10.80292\n",
      "Epoch: 103 | MSE: 10.79027\n",
      "Epoch: 104 | MSE: 10.77774\n",
      "Epoch: 105 | MSE: 10.76535\n",
      "Epoch: 106 | MSE: 10.75309\n",
      "Epoch: 107 | MSE: 10.74096\n",
      "Epoch: 108 | MSE: 10.72895\n",
      "Epoch: 109 | MSE: 10.71708\n",
      "Epoch: 110 | MSE: 10.70532\n",
      "Epoch: 111 | MSE: 10.69369\n",
      "Epoch: 112 | MSE: 10.68219\n",
      "Epoch: 113 | MSE: 10.67080\n",
      "Epoch: 114 | MSE: 10.65954\n",
      "Epoch: 115 | MSE: 10.64839\n",
      "Epoch: 116 | MSE: 10.63736\n",
      "Epoch: 117 | MSE: 10.62644\n",
      "Epoch: 118 | MSE: 10.61565\n",
      "Epoch: 119 | MSE: 10.60496\n",
      "Epoch: 120 | MSE: 10.59439\n",
      "Epoch: 121 | MSE: 10.58392\n",
      "Epoch: 122 | MSE: 10.57357\n",
      "Epoch: 123 | MSE: 10.56333\n",
      "Epoch: 124 | MSE: 10.55319\n",
      "Epoch: 125 | MSE: 10.54316\n",
      "Epoch: 126 | MSE: 10.53324\n",
      "Epoch: 127 | MSE: 10.52342\n",
      "Epoch: 128 | MSE: 10.51370\n",
      "Epoch: 129 | MSE: 10.50409\n",
      "Epoch: 130 | MSE: 10.49457\n",
      "Epoch: 131 | MSE: 10.48516\n",
      "Epoch: 132 | MSE: 10.47584\n",
      "Epoch: 133 | MSE: 10.46662\n",
      "Epoch: 134 | MSE: 10.45750\n",
      "Epoch: 135 | MSE: 10.44848\n",
      "Epoch: 136 | MSE: 10.43954\n",
      "Epoch: 137 | MSE: 10.43071\n",
      "Epoch: 138 | MSE: 10.42196\n",
      "Epoch: 139 | MSE: 10.41331\n",
      "Epoch: 140 | MSE: 10.40474\n",
      "Epoch: 141 | MSE: 10.39627\n",
      "Epoch: 142 | MSE: 10.38789\n",
      "Epoch: 143 | MSE: 10.37959\n",
      "Epoch: 144 | MSE: 10.37138\n",
      "Epoch: 145 | MSE: 10.36326\n",
      "Epoch: 146 | MSE: 10.35522\n",
      "Epoch: 147 | MSE: 10.34726\n",
      "Epoch: 148 | MSE: 10.33939\n",
      "Epoch: 149 | MSE: 10.33160\n",
      "Epoch: 150 | MSE: 10.32389\n",
      "Epoch: 151 | MSE: 10.31626\n",
      "Epoch: 152 | MSE: 10.30871\n",
      "Epoch: 153 | MSE: 10.30124\n",
      "Epoch: 154 | MSE: 10.29385\n",
      "Epoch: 155 | MSE: 10.28654\n",
      "Epoch: 156 | MSE: 10.27930\n",
      "Epoch: 157 | MSE: 10.27214\n",
      "Epoch: 158 | MSE: 10.26505\n",
      "Epoch: 159 | MSE: 10.25803\n",
      "Epoch: 160 | MSE: 10.25109\n",
      "Epoch: 161 | MSE: 10.24422\n",
      "Epoch: 162 | MSE: 10.23742\n",
      "Epoch: 163 | MSE: 10.23070\n",
      "Epoch: 164 | MSE: 10.22404\n",
      "Epoch: 165 | MSE: 10.21745\n",
      "Epoch: 166 | MSE: 10.21094\n",
      "Epoch: 167 | MSE: 10.20448\n",
      "Epoch: 168 | MSE: 10.19810\n",
      "Epoch: 169 | MSE: 10.19178\n",
      "Epoch: 170 | MSE: 10.18553\n",
      "Epoch: 171 | MSE: 10.17934\n",
      "Epoch: 172 | MSE: 10.17322\n",
      "Epoch: 173 | MSE: 10.16716\n",
      "Epoch: 174 | MSE: 10.16116\n",
      "Epoch: 175 | MSE: 10.15523\n",
      "Epoch: 176 | MSE: 10.14936\n",
      "Epoch: 177 | MSE: 10.14354\n",
      "Epoch: 178 | MSE: 10.13779\n",
      "Epoch: 179 | MSE: 10.13210\n",
      "Epoch: 180 | MSE: 10.12647\n",
      "Epoch: 181 | MSE: 10.12089\n",
      "Epoch: 182 | MSE: 10.11538\n",
      "Epoch: 183 | MSE: 10.10991\n",
      "Epoch: 184 | MSE: 10.10451\n",
      "Epoch: 185 | MSE: 10.09916\n",
      "Epoch: 186 | MSE: 10.09387\n",
      "Epoch: 187 | MSE: 10.08863\n",
      "Epoch: 188 | MSE: 10.08345\n",
      "Epoch: 189 | MSE: 10.07832\n",
      "Epoch: 190 | MSE: 10.07324\n",
      "Epoch: 191 | MSE: 10.06822\n",
      "Epoch: 192 | MSE: 10.06324\n",
      "Epoch: 193 | MSE: 10.05832\n",
      "Epoch: 194 | MSE: 10.05345\n",
      "Epoch: 195 | MSE: 10.04863\n",
      "Epoch: 196 | MSE: 10.04386\n",
      "Epoch: 197 | MSE: 10.03914\n",
      "Epoch: 198 | MSE: 10.03446\n",
      "Epoch: 199 | MSE: 10.02984\n",
      "Epoch: 200 | MSE: 10.02526\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression1(num_features=X_train.size(1))\n",
    "cost = train(model, \n",
    "             X_train, y_train, \n",
    "             num_epochs=200,\n",
    "             learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost)), cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 10.02526\n",
      "Test MSE: 14.37849\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "test_pred = model.forward(X_test)\n",
    "\n",
    "print('Train MSE: %.5f' % loss(train_pred, y_train))\n",
    "print('Test MSE: %.5f' % loss(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compare with analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights tensor([[-1.9090],\n",
      "        [-1.1661],\n",
      "        [ 1.4941],\n",
      "        [-1.8580],\n",
      "        [ 6.6503],\n",
      "        [ 0.1809],\n",
      "        [ 2.0131],\n",
      "        [ 0.0248]])\n",
      "Bias tensor([24.5209])\n"
     ]
    }
   ],
   "source": [
    "print('Weights', model.weights)\n",
    "print('Bias', model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical weights tensor([[-8.3062e+00],\n",
      "        [-1.1436e+01],\n",
      "        [ 3.2026e+00],\n",
      "        [ 2.1229e+00],\n",
      "        [ 6.6581e+00],\n",
      "        [ 1.9686e-01],\n",
      "        [ 2.0146e+00],\n",
      "        [ 8.6998e-03]])\n",
      "Analytical bias tensor([24.5209])\n"
     ]
    }
   ],
   "source": [
    "def analytical_solution(x, y):\n",
    "    Xb = torch.cat( (torch.ones((x.size(0), 1)), x), dim=1)\n",
    "    w = torch.zeros(x.size(1))\n",
    "    z = torch.inverse(torch.matmul(Xb.t(), Xb))\n",
    "    params = torch.matmul(z, torch.matmul(Xb.t(), y))\n",
    "    b, w = torch.tensor([params[0]]), params[1:].view(x.size(1), 1)\n",
    "    return w, b\n",
    "\n",
    "w, b = analytical_solution(X_train, y_train)\n",
    "print('Analytical weights', w)\n",
    "print('Analytical bias', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## (Ungraded) HW Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modify the `train()` function such that the dataset is shuffled prior to each epoch. Do you see a difference -- Yes/No? Try to come up with an explanation for your observation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}